{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alert-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "framed-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'layer_out/UltraNetDeepV1FloatBias/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "labeled-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv8_out = np.load(root + 'conv8.npy') # output of the last layer\n",
    "yololayer_io = np.load(root + 'yololayer_io.npy') # output for inference by yololayer\n",
    "yololayer_p = np.load(root + 'yololayer_p.npy') # output for training by yololayer\n",
    "infer_out = np.load(root + 'infer_out.npy') # same as yololayer_io\n",
    "train_out = np.load(root + 'train_out_0.npy') # same as yololayer_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pleasant-illustration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.equal(yololayer_io, infer_out).all())\n",
    "print(np.equal(yololayer_p, train_out).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bearing-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 36, 10, 20)\n",
      "(4, 1200, 6)\n",
      "(4, 6, 10, 20, 6)\n",
      "(4, 1200, 6)\n",
      "(4, 6, 10, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "print(conv8_out.shape)\n",
    "print(yololayer_io.shape)\n",
    "print(yololayer_p.shape)\n",
    "print(infer_out.shape)\n",
    "print(train_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "personalized-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Default configs of ultranet\n",
    "\n",
    "bs, _, ny, nx = conv8_out.shape\n",
    "p = conv8_out\n",
    "img_size = np.array([160, 320])\n",
    "anchors = [[20,20], [20,20], [20,20], [20,20], [20,20], [20,20]]\n",
    "p_torch = torch.tensor(p)\n",
    "na, no = len(anchors), 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deluxe-honey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the torch way to generate p for training\n",
    "# in yololayer\n",
    "\n",
    "p_torch = p_torch.view(bs, na, no, ny, nx)\n",
    "p_permute_torch = p_torch.permute(0, 1, 3, 4, 2)\n",
    "p_contiguous = p_permute_torch.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "behavioral-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing out the helper functions without torch\n",
    "def torch_view_5d(p, d0, d1, d2, d3, d4):\n",
    "    p_flatten = p.flatten()\n",
    "    p_new = np.zeros((d0, d1, d2, d3, d4))\n",
    "    for i0 in range(d0):\n",
    "        for i1 in range(d1):\n",
    "            for i2 in range(d2):\n",
    "                for i3 in range(d3):\n",
    "                    for i4 in range(d4):\n",
    "                        p_new[i0][i1][i2][i3][i4] = p_flatten[i0*d1*d2*d3*d4 + i1*d2*d3*d4 + i2*d3*d4 + i3*d4 +i4]\n",
    "    return p_new\n",
    "\n",
    "def torch_permute_01342(p):\n",
    "    ps = p.shape\n",
    "    p_new = np.zeros((ps[0], ps[1], ps[3], ps[4], ps[2]))\n",
    "    for i0 in range(ps[0]):\n",
    "        for i1 in range(ps[1]):\n",
    "            for i2 in range(ps[2]):\n",
    "                for i3 in range(ps[3]):\n",
    "                    for i4 in range(ps[4]):\n",
    "                        p_new[i0][i1][i3][i4][i2] = p[i0][i1][i2][i3][i4]\n",
    "    return p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liberal-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "p_np = torch_view_5d(p, bs, na, no, ny, nx)\n",
    "p_permute_np = torch_permute_01342(p_np)\n",
    "\n",
    "print(np.equal(p_np, p_torch.numpy()).all())\n",
    "print(np.equal(p_permute_np, p_permute_torch.numpy()).all())\n",
    "print(np.equal(p_permute_np, p_contiguous.numpy()).all())\n",
    "print(np.equal(p_permute_np, yololayer_p).all()) # show the numpy functions produces same output as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unavailable-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing out the helper functions with/without torch\n",
    "\n",
    "def create_grids_torch(img_size, ng, na, anchors):\n",
    "    nx, ny = ng\n",
    "    img_size = max(img_size)\n",
    "    stride = img_size / max(ng)\n",
    "\n",
    "    # build xy offsets\n",
    "    yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
    "    grid_xy = torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2))\n",
    "\n",
    "    # build wh gains\n",
    "    anchor_vec = torch.tensor(anchors / stride)\n",
    "    anchor_wh = anchor_vec.view(1, na, 1, 1, 2)\n",
    "    return grid_xy, anchor_wh\n",
    "\n",
    "def create_grids_np(img_size, ng, na, anchors):\n",
    "    nx, ny = ng\n",
    "    img_size = max(img_size)\n",
    "    stride = img_size / max(ng)\n",
    "    \n",
    "    grid_xy = np.zeros((1, 1, ny, nx, 2))\n",
    "    for i in range(ny):\n",
    "        for j in range(nx):\n",
    "            grid_xy[0][0][i][j] = [j, i]\n",
    "\n",
    "    anchor_vec = np.array(anchors / stride)\n",
    "    anchor_wh = torch_view_5d(anchor_vec, 1, na, 1, 1, 2)\n",
    "    return grid_xy, anchor_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powered-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xy_torch, anchor_wh_torch = create_grids_torch(img_size, (nx, ny), na, anchors)\n",
    "grid_xy_np, anchor_wh_np = create_grids_np(img_size, (nx, ny), na, anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loved-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.equal(grid_xy_torch.numpy(), grid_xy_np).all())\n",
    "print(np.equal(anchor_wh_torch.numpy(), anchor_wh_np).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "manual-curtis",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# writing out the helper functions with/without torch\n",
    "\n",
    "def return_io_torch(p, grid_xy, anchor_wh, img_size, nx, ny, no):\n",
    "    stride = max(img_size) / max((nx, ny))\n",
    "    io_torch = p.clone()  # inference output\n",
    "    io_torch[..., :2] = torch.sigmoid(io_torch[..., :2]) + grid_xy  # xy\n",
    "    io_torch[..., 2:4] = torch.exp(io_torch[..., 2:4]) * anchor_wh  # wh yolo method\n",
    "    io_torch[..., :4] *= stride\n",
    "\n",
    "    torch.sigmoid_(io_torch[..., 4:])\n",
    "\n",
    "    io_torch = io_torch.view(bs, -1, no)\n",
    "    return io_torch\n",
    "\n",
    "def sigmoid_np(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def return_io_np(p, grid_xy, anchor_wh, img_size, nx, ny, no):\n",
    "    stride = max(img_size) / max((nx, ny))\n",
    "    \n",
    "    ps = p.shape\n",
    "    io_np = np.zeros(ps)\n",
    "    for i0 in range(ps[0]):\n",
    "        for i1 in range(ps[1]):\n",
    "            for i2 in range(ps[2]):\n",
    "                for i3 in range(ps[3]):\n",
    "                    for i4 in range(ps[4]):\n",
    "                        io_np[i0][i1][i2][i3][i4] = p[i0][i1][i2][i3][i4]\n",
    "                        if i4 < 2:\n",
    "                            io_np[i0][i1][i2][i3][i4] = sigmoid_np(p[i0][i1][i2][i3][i4]) + grid_xy[0][0][i2][i3][i4]\n",
    "                        elif i4 < 4:\n",
    "                            io_np[i0][i1][i2][i3][i4] = np.e**(p[i0][i1][i2][i3][i4])*anchor_wh[0][i1][0][0][i4-2]\n",
    "                        \n",
    "                        if i4 < 4:\n",
    "                            io_np[i0][i1][i2][i3][i4] *= stride\n",
    "                        else:\n",
    "                            io_np[i0][i1][i2][i3][i4] = sigmoid_np(p[i0][i1][i2][i3][i4])\n",
    "    \n",
    "    io_np = io_np.reshape(bs, -1, no)\n",
    "    return io_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baking-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_torch = return_io_torch(p_contiguous, grid_xy_torch, anchor_wh_torch, img_size, nx, ny, no)\n",
    "io_np = return_io_np(p_permute_np, grid_xy_np, anchor_wh_np, img_size, nx, ny, no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weird-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.equal(p_permute_np, p_contiguous.numpy()).all())\n",
    "print(np.allclose(io_torch.numpy(), io_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "identical-mineral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(io_torch.numpy(), yololayer_io))\n",
    "print(np.allclose(io_np, yololayer_io))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "distinguished-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the entire yololayer\n",
    "def yololayer(p_out):\n",
    "    p_np = torch_view_5d(p_out, bs, na, no, ny, nx)\n",
    "    p_permute_np = torch_permute_01342(p_np)\n",
    "    grid_xy_np, anchor_wh_np = create_grids_np(img_size, (nx, ny), na, anchors)\n",
    "    io_np = return_io_np(p_permute_np, grid_xy_np, anchor_wh_np, img_size, nx, ny, no)\n",
    "    return io_np, p_permute_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "variable-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "yololayer_io_np, yololayer_p_np = yololayer(conv8_out)\n",
    "print(np.allclose(yololayer_io_np, yololayer_io))\n",
    "print(np.allclose(yololayer_p_np, yololayer_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-cambodia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
